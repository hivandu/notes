# 丰富选品方式



## 搜索系统
搜索系统，顾名思义就是提供大数据查找筛选功能的系统。在电商和O2O领域，搜索作为一个主要的流量入口，起到了至关重要的作用。



### 基本指标

对于搜索来说，主要的指标为准确率和召回率。下图是促销活动配置，我们其为例解释一下什么叫作准确率和召回率。

![image-20210227133735352](http://qiniu.hivan.me/picGo/20210227133735.png)





图中的整体部分为商品数据的全集，其中包括不相关和相关的内容，如图：

![image-20210227133743039](http://qiniu.hivan.me/picGo/20210227133743.png)



准确率：搜索结果中相关内容的比例，即图中A的部分。

召回率：搜索结果占整体内容的比例，即A+B。

由此可以看出，最完美的结果是A足够大且B足够小，但在实际实现中我们会发现上述两个指标是相反的（召回率越高，准确率会越低），需要通过规则来平衡这部分。



### 基础结构

搜索系统主要的组成部分有以下几块：

- 切词逻辑
- 词库
- 基础信息
- 加权规则
- 排序展示逻辑



整体流程如图：

![image-20210227133805160](http://qiniu.hivan.me/picGo/20210227133805.png)



名词解释：

- 关键词（query）：指用户在搜索框中输入的内容
- 切词：又叫分词，是根据词库/词典将一段文本进行切分，以便机器识别的过程
- 分词：指用于切词的分词
- 加权：将检索结果集按照一定的维度、规则进行打分叫作加权
- 索引：商品信息存储时需要建立索引，索引为每个商品的标识，方便在大数据量的情况下快速查找筛选



### 应用场景

搜索的应用一般有两种：全文检索和Suggest（推荐）。其中，Suggest的规则比全文检索要简单一些。由于Suggest一般支持模糊查询，因此要考虑服务上是独立还是共用一套。



### 流程结构

**切词**

切词，又叫“分词”，用于将用户输入的非结构化字符变成机器可识别的词组。

市面上有很多成熟的切词组件。切词逻辑有很多种，如根据字符、概率等切词，电商和O2O一般使用字符串切词的方式进行处理。关于切词的方法，最基础的有最大正相匹配、最大逆向匹配和双向匹配等，具体的内容可以百度查询。切词工具是根据词库中的词典将字符进行切分，一般开源的切词工具都有默认的词库和自定义词库两种，我们可通过添加自定义词库来完善补充。

这里面需要强调的是切词时候的过滤，尤其生鲜类、非标品情况下特别需要注意。

- 单字词、助词之类的是否要过滤掉，如米、面和油等。
- 别名情况的处理，尤其是生鲜类。比如北京的油菜，在上海叫上海青，在重庆叫漂儿白。



**检索**

接下来就需要匹配检索结果集了。根据切出的词语进行匹配，匹配到的商品信息集合为检索结果集。结果集需要做检索、过滤和标记3个步骤。

检索项包括但不限于：

- 商品名称
- 商品标题、副标题
- 商品描述
- 商品参数、规格
- 商品品牌（生鲜、副食品类尤为重要）
- 商品品类（一级类、二级类）
- 别名关联商品
- 促销类型

成熟的系统不仅仅能实现用户的基本商品检索，还应该根据关键词进行意图分析并进行查询转换。

这里不以网鱼产品进行举例了，暂还未有实现。我们先以一个生鲜电商系统为例（最近有在研究盒马）：当用户搜索“猪肉”时，用户希望获得的不是含有“猪肉”词语的商品，而是猪肉的各个部位、猪肉级别等信息，这时应该将其转化为“后臀尖”“前臀尖”“里脊”“一级白条”等词语进行检索，而不是匹配“猪肉”。意图分析主要有以下两个方面：

- 行为模式分析
- 用户画像分类



**去重和过滤**

获取的结果集需要经过去重、过滤的处理。此部分可以在加权打分后进行处理，也可以安排在初选结果后处理。

- 同一个商品被多个词语命中，则需要去重。
- 现实中的商品搜索可能会根据不同的场景构建所谓的“小搜索”，如按照类目、品类和定制化场景等搜索。因此，针对不同的搜索场景，可能会有不同的过滤、去重条件，也可以在构建数据的时候使用不同的库进行处理。

O2O场景需要按照一定区域概念（城市、商圈等）进行过滤。

- 售罄商品需要过滤
- 下线商品需要过滤



**标记和加权**

在检索完成后需要对数据进行标记，以便后续做加权时使用。此步也可以在做加权处理的时候同步进行。

加权是整个流程中最重要的步骤。加权的目的是根据模型确定结果集中各个商品的排序优先级。加权的维度有很多，根据不同的场景考虑会有所区别。

加权因子主要分为以下几个维度：

- 相关度
- 商业化因素
- 个性化因素
- 人为因素
- 数据模型统计



**计算相关度**

最后是计算相关度，这里指的是分词的相关度，包括文本匹配、词间距、是否是中心词和品牌词等。

中心词的概念是是否命中了核心的词语，中心词和品牌词也需要有对应的词库进行维护更新。词间距是计算相关性的一个维度，比如一段文本中包含清华、大学，“清华大学×××××××”与“清华×××××××大学”相比，肯定是前者相关性更高一些。

这里面有几点需要注意。

- 关键词被完整匹配和部分匹配的权重是不同的
- 单词命中和多词命中同一商品也需要考虑权重情况



### 商业化因素

业务场景下需要关注的因素称为商业化因素。

- 商品库存
- 是否新品（考虑到新品的特殊性，也可以将此权重独立打分）
- 商品销量
- 是否促销商品
- 销售额
- 商品分类
- 商品品牌
- CTR（Click-Through Rate，点击率，广告类的商品要考量）
- 所属平台（POP、自营）
- 区域（O2O属性）
- 终端情况（手机、PC）



### 个性化因素

按照个人使用的情况进行个性化排序，做到所谓的“千人千面”，包括下单数据分析等。这部分与意图分析的情况类似。



### 人为因素

在日常运营过程中，有很多需要做强制人为干预的事情（如人工置顶），因此在加权的时候需要考虑此类行为。



### 数据模型统计

可以根据用户的一些行为数据或者埋点数据进行分析，提供综合排名靠前的商品或者分类做单独加权权重。主要包括：

- 用户/门店点击
- 用户收藏
- 购买数



然后，需要根据加权的情况和一些特殊的处理，对最终输出的结果做排序调整。这里提供两种方法供参考：

- 可以按照加权打分的分值之和的高低做排序。这样做比较直接，但在后续调整的过程中，验证规则时容易混淆不清
- 按不同的权重维度单独计算，生成一个长位数的标识符，每个权重在标识符上有它自己的位置。按照优先级的顺序从左到右依次排列。考虑到机器计算的易用性，可以在加权时使用十进制，然后统计时转换成二进制。位数和排序可以根据具体业务场景制订，如图：

![image-20210227133917496](http://qiniu.hivan.me/picGo/20210227133917.png)



最后，在算法中要考虑相同因子下的打散，比如同一个分类的商品排序需要按照一定比例分布在不同地方，避免一次性展示过多同类商品。

如果系统能力富足，也可以增加单独的反作弊模块来处理一些恶意刷单、刷榜的情况（网鱼如果走平台化，对接不同商品提供商，则此项必须有）。





### 各系统关联

搜索系统主要为用户端提供搜索结果的输出，输入来自于相关的下游系统。当搜索场景进一步细分时，要考虑更多数据的对接和分类，结构如图：

![image-20210227133946156](http://qiniu.hivan.me/picGo/20210227133946.png)



在设计时有几个需要注意的地方。

- 搜索数据比较庞大，直接使用API调用实时数据对系统压力过大，一般可采取搜索自建索引库、定时（比如15分钟）从相关系统拉取数据的方式
- 可以基于不同的场景提供不同的索引库来实现，避免逻辑耦合不好分离而导致无法做个性化
- 考虑到服务压力，用户端在调用suggest时，建议延迟几秒请求数据
- 分词词库的维护也依赖于定期从相关系统中获取补充



## 推荐

随着生活水平的日益提高，人们对于商品的要求也都趋于个性化。每个人对于商品都有自己的喜好和习惯，而抓住并养成习惯也是电商平台推广宣传的有效手段，就这样，推荐系统应运而生。

推荐，顾名思义，按照用户的喜好和行为推荐，可以满足用户诉求和需要的商品，以求达到用户购买的目的。从广义上来讲，所有主动推送给用户的商品信息都可以视作推荐的范畴，包括在POS内对销售人员进行用户喜好推荐也属于这个范畴，而这里面具有商业变现能力的商品推荐又叫作广告。广告的管理一般会由单独的广告系统负责，我们这里主要讲解下除广告以外的商品推荐内容。



### 推荐系统的评估指标

推荐系统从根本上是为了解决营销选品决策的问题，因此就需要有一些指标来衡量和评估效果，为后续的推荐策略参数调整和推荐方式优化提供依据。常见推荐系统的指标和搜索的指标比较类似，包括准确率、召回率和新颖度等。

- 准确率（Precision）：表示召回的商品中推荐正确的商品占整体召回商品的百分比
- 召回率（Recall）：表示召回的商品占整体商品的百分比
- 新颖度：表示推荐长尾区间的商品情况，如果推荐商品都是热门商品，即新颖度很低，反之则新颖度较高
- CTR：点击率，也是广告系统的衡量指标之一
- CVR：转化率，指从用户点击推荐商品到完成购买的转化率，公式为CVR=（转化量/点击量）×100%



### 推荐场景差异化

接下来看一下推荐系统在电商平台用户端都有哪些常见展现形式，如图：

![image-20210227134049992](http://qiniu.hivan.me/picGo/20210227134050.png)



推荐的使用一般放在售前环节，通过浏览时的推荐提高用户的购买率，少部分会在购买完成后提示用户，增加二次消费的概率。网吧内的销售通道不同于小蓝杯和猩便利等，它是全天候的售卖平台，但在实际消费的时候用户会有不同的购买场景，不同的购买场景对于推荐的要求也是有差异的。

- 时间维度：包括节假期、促销周期等，对于O2O甚至还需要更细致的时间划分，比如早中晚、加班等。不同的时间维度用户对于购买的诉求不一样，推荐给用户的商品也不应该完全相同
- 地点维度：地点维度更多会影响到发货的周期，本地仓库/商家是否有货，决定是否可以早一点将货送到用户的手里

推荐系统要达到场景推荐差异化，就要根据不同情况下获取的不同数据进行分析处理。推荐系统的底层数据源和搜索一样，都是来自于各个业务系统的，推荐系统本身并不会产生业务数据。推荐系统主要是分析人与物之间的关系，因此数据都是围绕这两个点进行延伸的。

人指的就是用户本身的信息，包括用户自身的基础信息，比如用户名、联系方式、地址和收藏等，还有消费信息，比如订单信息、会员信息等。这些信息可以对用户在系统中的实体进行初步的构建，以便推荐系统可以通过这些信息分析出人的“特性”。而物品也就是商品信息，商品数据主要是商品的基础信息、促销信息。除此之外，对于埋点的数据也需要进行统计，结合上述内容一起分析。埋点信息包括访问数据、点击数据等。

很多时候，一些新的用户和新上架商品并没有历史数据可以追溯，这样就无法提取特征，也就是我们常说的“冷启动”。冷启动的问题也会影响到使用哪种推荐策略，因为不同的推荐策略可能对于数据量的要求也不一样。某些策略依赖于大量的数据进行分析，这个时候不处理冷启动的问题就无法积累数据。为了应对冷启动的问题，我们需要找到一些方法，根本思路就是通过变形或者转化来获取特殊的数据源，以解决无数据的问题。

第一种方式提供相对稳定的数据筛选结果，最为常见的例子就是热销排行榜。这种方式是假定所有用户属于一个整体的集合，在这个集合下最关注的商品就是热销品。考虑到人群的从众心理，给新用户推荐热销商品其实是一种相对稳妥的方式，实际证明新用户在冷启动阶段对于热销品有更大的购买动力，而老用户则会更多考虑长尾推荐。数据收集到一定程度后，再将推荐数据转化为更为精细的个性化推荐内容。很多平台的发现页面就是通过这种方式去处理早期数据不全的情况。

第二种则是利用用户前期注册时留下的信息进行判断。目前很多平台都会在初始阶段让用户填写一些个人信息和兴趣爱好，这种手段在音乐或阅读类平台用的比较多。通过用户填写的信息来初步构建特征，进行商品推荐的匹配。除了用户本身在平台填写的信息外，目前绝大多数都会使用第三方账户登录，如微信、支付宝等。通过第三方账户登录，在用户授权的情况下也可以导入部分用户行为数据辅助分析用户特征。但由于信息的匮乏，这种推荐会造成颗粒度很粗，可能导致很大一部分用户看到的商品是完全一样的，但实际上他们还是有一定区别的。

此外也可以结合上面两种情况来获取信息，比如提供一些特定分类，如热销的商品，让用户进行喜好选择，根据用户的选择匹配相似的商品数据。这样冷启动时可以更好地提供相对精准的推荐数据。不过这个方法对于前期提供选择的商品集合有一定的要求，不能过分地从单一的分类中获取商品，平台要提供品类更丰富的选项，以便后续分析时可以更加准确。

上面讲到的是新用户冷启动的数据获取方案，除了用户的冷启动，还有商品的冷启动。对于上新的商品，我们缺乏对于商品购买人群的数据特征，这就需要通过冷启动获取关联数据，如图：

<img src="http://qiniu.hivan.me/picGo/20210227134100.png" alt="image-20210227134100008" style="zoom:50%;" />



获取数据的思路和用户冷启动所获取数据类似，最基础的方式就是提供特殊标签，如“新品”。通过标签提高权重以达到展示推荐的目的。此外，由于商品的信息是由内部运营人员进行录入的，因此我们可以通过人为的方式获取到更多商品的基础信息。推荐系统可以通过关键词或者标签（Tag）的方式获取商品的关键信息，计算新品与老品之间的相似度来进行推荐。

同时我们也可以通过获取第三方的数据来判断用户情况，如获取已安装应用情况，判断性别、年龄和爱好等信息。总结下来，冷启动主要是通过3个方向获取数据：引导用户自填、运营人工分类和第三方获取。





### 推荐策略的“演变”

判断用户喜欢的商品并进行推荐就是建立人与商品的关系。以上提到的所有元数据（包括人的信息和商品的信息）都需要根据推荐策略进行关联。

推荐的策略发展至今，已经由简单的概率分析延伸为现在比较流行的深度学习。我们讲到，推荐的核心就是建立人与商品的关系，关系较近的则认为它们相关度较高，关系较远则认为相关度较低。

在人与商品的关系中还包含人与人、商品与商品的关系，由此构建出一个关系图谱。比如我们常说的用户画像，就是设定人与人关系的基础数据。按照人和商品的维度，我们可以建立一个二维的坐标系，根据坐标远近来判断相关度进而产生推荐的商品信息。由于推荐系统对于算法的要求比一般的业务系统要高，因此这里更多从产品维度来介绍推荐策略和算法的一些情况。想深入了解一些算法的话，请自行研究。

之前提到，推荐策略即是判断人与商品之间的各种关系，关系越近则认为匹配度越高。那如何去判断关系的远近呢？对于这个核心的问题的解决，推荐系统也一直在进行发展演变，随着技术的提升，推荐系统也变得越来越智能化。



**无系统推荐**

在没有系统推荐的时候，推荐系统更多的是完成人工配置商品的过程。通过人工设定固定商品进行推荐，目前一些不具备推荐算法能力的平台依然会使用此类方法。这样的方式固然可以实现推荐商品，但效率和效果不佳，于是就出现了基于内容的推荐策略。



**基于内容推荐**

基于内容推荐的思路是将所有的商品、内容和人等基础实体进行标签标记，系统通过标记的商品属性特征进行分类，当用户进行购买时，系统通过购买的商品判断具备相同属性或者相似属性的商品集合，再通过消重、过滤等规则，完成最终的推荐列表。基于内容的推荐实际上是判断商品与商品的固定关系，我们以一个实例看一下策略的处理方式。

以当前网鱼的饮品（包含手工饮品和包装饮品）为例，我们基于饮品的相关信息为所有饮品制订标签特征，包括但不限于商品名称、品名关键词、原料、分类、定价、饮品关键词等。通过标签整理，我们能得到3个饮品的特征集，见表（**商品的特征集**）：

**商品的特征集**

| **商品** | **品名关键词**   | **种类** | **分类** | **定价（元）** | **饮品关键词**   |
| -------- | ---------------- | -------- | -------- | -------------- | ---------------- |
| 商品A    | 咖啡、美式       | 咖啡     | 咖啡     | 15.0           | 咖啡、调制       |
| 商品B    | 雀巢、咖啡       | 咖啡     | 其他类   | 8.0            | 拿铁、咖啡、罐装 |
| 商品C    | 手工、饮品、调制 | 柠檬茶   | 特调     | 18.0           | 调制、可乐、柠檬 |



如果用户购买商品B，则购买完成以后可以推荐商品A给用户，因为商品A和商品B具备相同或相似的属性（包括品名关键词、饮品关键词），而商品C则和商品B相差较远，因此不进行推荐。

这里面一般是通过加权的方式来判断多个属性是否和购买商品的特征相似或相同，其中，加权以及消重等规则与搜索使用的方法类似。特别说明一下，推荐策略做加权同样需要考虑词频的因素，一般使用的概念是TF-IDF（Term Frequency-Inverse Document Frequency）。TF为词频，即关键词在当前文本中出现的次数，这里包括所有特征属性；IDF为逆文本频率指数，指在所有文本属性中出现次数的倒数。计算方式是TF×IDF，这项指标表示我们认为在当前文本中出现的高频词是高权重的，但如果该关键词在所有文档中出现频率都高，则认为该词不具备特殊意义，故而权重是很低的。上述表格中的“咖啡”词汇，如果只在当前文本特征中出现次数较高，则属于高权重；如果在所有语料文本中都出现很多次，则认为它不应该代表特定意义，只是一个通用的词汇，权重应该降低。

基于内容过滤的规则比较简单，初期搭建时可以快速实现推荐功能的自动化，节省人力。但问题也是明显的，首先需要对所有的商品构建特征标签，工作量巨大，同时，由于推荐策略的颗粒度和构建特征的多少有直接关系，因此会造成颗粒度过于粗糙、推荐商品不准确的问题。如果平台本身不具备太多推荐算法的能力，可以通过人工配置加基于内容推荐的方式获取推荐的基本自动化能力。

?> 这里还需要强(TÙ)调(CÁO)一点，商品管理上对于分类及关键词定义是后期推荐的先决条件，如果分类不严谨、不准确，将对后期的数据分析和推荐造成莫大的障碍。就比如上述例子中，商品B其实是“自采-雀巢咖啡（丝滑拿铁）”，但是分类上却被分到了其他分类，单从三级分类的名称上来看，根本无法清楚这个商品被分到了一个什么样的分类里。所有数据的基础都源自元数据质量，而数据质量的提高除了数据治理这一项之外，更重要的是录入和管理基础信息的运营人员的素质。



**基于用户行为推荐**

基于固定的内容无法获取更加精准的推荐商品，那么我们可以换个角度来看待这个问题。我们把基于商品与商品的固定关系转变成参考人和商品、商品和商品之间的关系来进行推荐策略的构建，即基于用户的行为来判断商品的关系。

用户的行为具有复杂多变的特性，但不代表它没有规律可循。常见的基于用户行为的策略主要分为关联规则和协同过滤。



**关联规则**

关联规则是指通过收集的每个用户的一段购买数据，可以得出买过商品A的所有用户以及这些用户同时买了哪些其他商品，然后将这些商品合并就得出了一个同时被购买商品列表的排序。基于商品列表进行消重、去除低关联商品等，最终实现推荐商品列表输出。关联规则的核心策略就是计算关联度。关联度有两个常用指标：支持度和置信度。

- 支持度（Support）：买过商品A、同时买过商品B的人数/总的人数
- 置信度（Confidence）：买过商品A、同时买过商品B的人数/买过商品A的人数



计算公式：$关联度=Support×Confidence$。下面我们举一个例子，看一下算法是如何运行的。**dubin**购买了商品item1，这个时候我们想计算item5是否应该推荐。根据公式，我们来计算一下支持度和置信度。支持度$Support=2/4$，置信度$Confidence=2/2$，需要说明的是，计算时要除去dubin本人。这样我们可以得到$Support=0.5$，$Confidence=1$，因此item5对于item1的关联度就是$0.5×1=0.5$，见下表（**计算关联度**）：



**计算关联度**



|           | **Item1** | **Item2** | **Item3** | **Item4** | **Item5** |
| --------- | --------- | --------- | --------- | --------- | --------- |
| **dubin** | 1         | 0         | 0         | 0         | `?`       |
| **User1** | 1         | 0         | 1         | 0         | 1         |
| **User2** | 1         | 0         | 1         | 0         | 1         |
| **User3** | 0         | 0         | 0         | 1         | 1         |
| **User4** | 0         | 1         |           | 0         | 0         |



从上面的例子我们可以看到，通过关联度可以发现人们最常用的购买组合是哪些。这对于一些品类单一的商品结构是非常适用的，策略的逻辑本身并不复杂，对技术的要求也不会特别高。但从计算量上来看，它需要对所有的商品进行遍历计算才能获取所有的指标，这对于离线的数据挖掘成本来说过大了。



**协同过滤**

显而易见，将关联规则作为主要的算法是有些不合适的，我们需要寻找一个效率更高、成本更低的算法来作为主要的推荐算法，协同过滤就是目前主流的推荐算法。

协同过滤的主要原理是运用群体的协同智慧，旨在通过一个群体的喜好判断来确定单体的特征和情况。这个群体既可以是用户群体，也可以是商品群体。

协同过滤有几个基本的假设：

- 用户会对物品给出评价（隐性或显性）
- 用户偏好一定时间内不会发生变化

协同过滤的处理主要包括两个部分：评测和群体搜索。我们来看一下协同过滤的处理流程，如图：

![image-20210227134333451](http://qiniu.hivan.me/picGo/20210227134333.png)



获取所有的用户信息，用户信息包括用户自行填写的内容、评价和消费记录等信息。对于新用户，可以通过冷启动的方式获取数据。同时要对用户的数据进行一些基本的预处理，主要的预处理为降噪和归一化。降噪主要是剔除一些异常数据，比如用户的误操作、未支付订单等；而归一化的目的是保证推荐结果在进行推荐计算的时候不会受到极值的影响而出现过大偏差。比如，订单的数量就远大于收藏的数量，需要将这样的信息通过处理变为一个相对合理的区间范围，一般会将归一化的数据分布变为［0,1］区间。常用的归一化方法有很多，比如对数归一、指数归一等。归一化的概念和地图的比例尺有些相似，其目的是在保证相对关系的情况下，将所有样本缩放到一定范围内，以便进行计算。

数据处理完毕后，推荐系统就会根据信息对用户或商品进行评估打分。这里面主要是基于已知的用户或者商品集合的信息，判断与当前用户或商品的相似度。推荐算法基于不同的相似度得到每个集合的分值，根据计算的分值判断与当前用户或商品的邻近群体。通过将邻近群体和当前商品或用户进行比对，完成推荐结果的输出。

相似度的计算也是推荐算法的核心，相似度主要是指当前群体和已知群体之间的邻近程度。邻近算法也是随着技术发展逐步发展起来的，这里我们以KNN算法为例来看一下邻近算法的原理。

KNN（全称K-NearestNeighbor，K-邻近算法）意思是K个最近的邻居，指的是每个样本都可以用它最接近的K个邻居来代表。该策略的思路是通过指定一个数量范围K，判断最相似的K个商品具备的共有特征，则认为查询的商品或用户本身也具有这个特征。简单地说，就是认为你跟你附近K个最近的群体具有相同特征。

KNN算法的计算过程分为三步：

- 计算待分类物体与其他物体之间的距离
- 统计距离最近的K个邻居
- 对于K个最近的邻居，它们属于哪个分类最多，待分类物体就属于哪一类

![image-20210227134347874](http://qiniu.hivan.me/picGo/20210227134347.png)

如上图所示，首先我们将所有的样本数据与当前需要比对的样本进行距离测算，根据测算距离生成一个由近及远的列表。所有样本比对完毕后，从当前列表中选取K个样本并判断当前样本中多数项的属性特征，将该属性特征赋予被比对的商品，完成推荐结果输出。我们上图来看一下邻近算法的运行原理。当范围K选取的是值C1时，我们认为当前比对样本的特征应该是圆形，因为在范围内圆形占多数项；而当我们把范围K的值调整为C2时，我们发现比对样的特征变为了正方形，因此KNN的邻近算法会因为K的选取范围而使结果产生巨大变化。

?> 有兴趣研究的同学可以参看我之前写的一篇学习手稿：『根据打斗和接吻次数来划分电影类型』**（私聊获取地址）**

虽然目前的主流协同过滤还是使用计算相似度来进行推荐，但策略上已经发生了变化。协同过滤按维度分为基于用户维度和基于商品维度。基于用户维度（User-Based：Row Similarity）是指以用户为参照物来判断和当前用户相似的用户群体的喜好，从而向当前用户推荐相似用户群体喜好且当前用户未曾购买的商品。如果我们把用户和商品的关系列为一个矩阵，则按用户维度来看，它也可以看做是行相似性。下表（**基于用户维度推荐商品**）内容所示，用户A购买时，通过查询比对，发现用户A和用户C是相似群体，因此根据用户C的特征推荐商品D给用户A。

**基于用户维度推荐商品**

| **用户/物品** | **物品A** | **物品B** | **物品C** | **物品D** |
| ------------- | --------- | --------- | --------- | --------- |
| **dubin**     | ✔️️         |           | ✔️️         | 推荐      |
| **User1**     |           | ✔️️         |           |           |
| **User2**     | ✔️️         |           | ✔️️         | ✔️️         |



基于商品维度（Item-Based：Column Similarity）也叫作基于项目维度，项目通常指除人以外的实体，在商品中心，则代表商品维度，而在新闻、音乐类平台中则代表其他的实体。与基于用户维度不同的是，基于项目维度是以商品（下面将“项目”统一称作“商品”）为参照物来判断找到和当前物品偏好相似的物品，然后根据用户历史的喜好情况推荐相似品。我们还用关系矩阵来看基于商品维度的处理方式。购买商品A的用户和购买商品D的人群很相似，因此当用户购买A时，我们可以推荐商品D给用户，见下表（**基于商品维度推荐商品）**。因此基于商品维度又叫作列相似性。



**基于商品维度推荐商品**

| **用户/物品** | **物品A** | **物品B** | **物品C** | **物品D** |
| ------------- | --------- | --------- | --------- | --------- |
| **dubin**     | ✔️️         |           | ✔️️         | 推荐      |
| **User1**     | ✔️️         | ✔️️         |           | ✔️️         |
| **User2**     | ✔️️         |           | ✔️️         | ✔️️         |





两种维度的算法各有优缺点，衡量使用哪个算法的标准主要是选取参照物较少的维度。例如，电商平台相对于庞大的用户群体来说，商品相对固定，商品之间的关系变化也较少，因此以商品为参照物可以大大减少计算的量级和复杂度；而新闻类则相反，用户相对于内容来说更为稳定，则使用用户为参照物，处理起来更为便捷。同时，基于商品维度的算法相对于基于用户维度的算法，其结果集更为稳定，但丰富性相对较低。因此，如何取舍要依赖于平台对推荐的实际业务要求。更多的时候可以使用混合算法，即按照一定的配比，从多种算法中获取商品，并进行去重、加权和排序等。

一般来说，在使用协同过滤算法的时候有几个技巧。

- 低频的物品可以过滤，减少杂质对整体计算的影响
- 降低高频热门物品的权重，避免出现大量重复推荐、显示高频商品的问题
- 打分的分值可以随着时间的递进而衰减，即越靠近当前越高



这里简单介绍几种算法的公式，具体的算法细节自行搜索了解。

Cosine-based Similarity（余弦相似度）：常用于计算文档数据相似度。
$$
Sim(i,j) = cos(i,j)=\frac{i*j}{||i||_2*||j||_2}
$$


Pearson Correlation Similarity（皮尔逊相似度）：计算两个定距变量的相似度。
$$
sim(i,j) = \frac{{\sum_{u\in U}}(R_{u,i}-\overline R_i)(R_{u,j}-\overline R_j)}{{\sqrt{{\sum_{u\in U}}(R_{u,i}-\overline R_i)^2}}{\sqrt{{\sum_{u\in U}}(R_{u,j}-\overline R_j)^2}}}
$$




Adjusted Cosine Similarity （校正余弦相似度）：修正了余弦相似度算法对于绝对数值不敏感的问题。
$$
sim(i,j) = \frac{{\sum_{u\in U}}(R_{u,i}-\overline R_u)(R_{u,j}-\overline R_u)}{{\sqrt{{\sum_{u\in U}}(R_{u,i}-\overline R_u)^2}}{\sqrt{{\sum_{u\in U}}(R_{u,j}-\overline R_u)^2}}}
$$




### 推荐系统架构

推荐系统按照处理流程可划分为若干层。从效果来看，业务特征加特殊特征的精细度决定效果的最终上限：

- 特征层：负责沉淀所有特征内容
- 样本层：提供样本选取和训练
- 模型层：提供模型算法
- 召回层：负责召回数据
- 排序层：提供打分、排序和去重等功能

结构如图：

![image-20210227140934765](http://qiniu.hivan.me/picGo/20210227140934.png)



## 本期系统交互情况

由于引入了搜索和推荐系统，用户在查找商品时，平台能够更精确地提供用户想要的商品信息，有效地提高了用户选品的效率。搜索对所有相关商品数据（包括但不限于商品，还有订单、促销和访问统计等）进行遍历计算，完成后存入搜索库中，当前台用户从相关页面访问时，判断用户身份，根据用户情况对搜索的关键词和内容进行处理加工并返回最终的搜索结果。

推荐的流程也大致相同，根据商品的基础信息分析用户的购买习惯和倾向，根据前台用户端返回的浏览信息进行判断。用户端根据返回的推荐信息进行展示，引导门店选取或用户购买。

这里，搜索推荐的商品主要考虑系统计算的逻辑，结构变化后如图：

![image-20210227140954710](http://qiniu.hivan.me/picGo/20210227140954.png)



上图中没有涉及人为调控管理的后台，因此从使用角色上看，并没有增加额外的人员编制。但如果业务需要，可以根据情况提供后台，以便运营专员进行人为的调控（比如搜索置顶）。另外，广告的行为也没有涵盖在当前图中，原则上由广告系统提供商品信息，按照约定的权重展示广告并统计流量。